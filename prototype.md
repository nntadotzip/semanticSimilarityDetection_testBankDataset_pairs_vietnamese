# Prototype

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The below figure is the brief version describes the full system proposed by this study. The color notation used in accordance with the proposed methodology is defined as follows:

- Yellow area: Data Formation Phase.
- Pink area: Augmentation Phase.
- Blue area: Experiment Phase.
- Squared Component: Automation.
- Rounded Component: On Manual.
- Green-background Component: Proposed by this thesis. Violet-background Component: Inheritance from publications.

![Proposed System – Brief version.](https://github.com/nntadotzip/semanticSimilarityDetection_testBankDataset_pairs_vietnamese/blob/main/mitm_thesis_prototype_ver3.drawio_brief_2.png?raw=true)

<p align="justify">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; As can be seen, the proposed methodology consists of 03 phases which are Dataset Formation, Augmentation, and Experiment. The output of the current stage can be considered as the input of the following one. First, the Dataset Formation describes the processes of creating new datasets from scratch that satisfies the requirements of the other phases. Two distinct datasets – named LABEL=0 and LABEL=1 respectively – are the end result of this procedure, one of which contains unique couples of sentences and the other contains pairs that are semantically related. The LABEL=1 dataset is then augmented using the Synonym Augmentation, the Definition Augmentation, and the Backtranslation methods, resulting in an increase in both quantity and quality. The product of this phase is the sets of similar augmented pairings named AUGMENTED DATASETS LABEL=1, which are devoid of the original LABEL=1 dataset. Last, 12 experiments are conducted using BERT [1] and PhoBERT [2] models to evaluate the efficiency among the proposed augmentation methods. The tests also include the comparison in performance between Feature Extraction and Fine-tuning approaches on the mentioned augmenting methods.</p>

<p align="justify">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; One of the biggest obstacles of every problem is the initial point. A dataset, which is a prerequisite for making the augmentation happens, is also the starting point of this study. In fact, NLP materials for Vietnamese is not as robust as they are for the high-resource languages which engenders the lack of Vietnamese publication dataset for this Similarity Detection task. Thus, the dataset formation must start with crawling data. Data is crawled from VietJack – one of the most visited educational websites in Viet Nam that contains courses, documents, and test banks. Although there are tons of Vietnamese test banks available online that can be used instead, VietJack is chosen mainly because of the friendly HTML structures that relieve the coding effort rather than for any other factor that might causes biases. Moving to the next one, Pairing contributes mostly to the success of the augmentations. In spite of combining every sentence, this process uses the strategy of pairing questions with defined scopes. Particularly, pairs are formed within a lesson or subject, not across them. The filtering process, which comes next, is crucial in easing the strain of the manual labeling step. Instead of categorizing all pairings, a threshold is established to separate out the ones that have a high likelihood of being similar, hence, labeling effort is reduced.</p>

<p align="justify">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Moving to the primary phase – Augmentation, there are 03 augmentation methods that are taken into account. Synonym Replacement and Definition Replacement are the new method proposed by this thesis. Backtranslation – a well-known augmenting technique whose applicability has already been proven by studies ([3], [4], [5], [6], [7], [8], [9], etc.), otherwise, gets involved in order to compare the utility among three mentioned methods.</p>

![Proposed Prototype – Full version.](https://github.com/nntadotzip/semanticSimilarityDetection_testBankDataset_pairs_vietnamese/blob/main/mitm_thesis_prototype_ver3.drawio_FULL.png?raw=true)

<p align="justify">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Synonym Replacement and Definition Replacement share some processes which are Word Segmenter and Find Shared Words. The substituting terms could be meaningless without this Word Segmenter since the white space used to separate the syllables that make up words in Vietnamese is a poor indication of word boundaries. The purpose of the Find Shared Words process is to prevent the meaning of augmented sentences from being drifted too far. In short, only the shared words are altered in the replacement methods. It is because all EDA tests demonstrated that performance attains the great results with low values of changed words [10]. For each method, there exists SBERT filtering and duplication removal steps. These steps are crucial as data is processed in bulk that makes it difficult to control whether the replaced phrases are too different or identical from the originals.</p>

<p align="justify">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Synonym Replacement translates the shared words outputted from the previous step into English, then searches the synonym for these words and translates them back to Vietnamese. After the translation, a cosine filtering is applied for comparing the similarity between the original word and the synonym one in order to eliminate the unexpected outlier during the transformation. Translation is involved due to the limitation of Vietnamese materials in the field.</p>

<p align="justify">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Definition Replacement, besides, does not look up for words directly after the sets of shared words are formed. The majority time of this method is to finding definition to replace. While some words share the same spelling, their meanings vary depending on the word type. Hence, to choose the correct phrase to replace, identifying the part-of-speech (P.O.S) of that word in the sentence helps enhance the efficacy of the method. The definitions are crawled from Vietgle (https://tratu.coviet.vn) – a reliable and widely used website by Vietnamese community. Along with being reliable, Vietgle's library offers definitions for words with similar spelling but distinct word types. The shared words in the original pairings are then substituted once the definition sets have been created, and after that, cosine similarity and duplication removal are applied.</p>

<p align="justify">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; As mentioned earlier, Backtranslation technique is engaged for comparison purpose. There is no modification from the original method. The diagram is provided to show its implementation within this study for transparentizing the utility that can consolidate the final comparing results.</p>

<p align="justify">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Experiment happens once all the augmentations are done. BERT [4] and PhoBERT [5] models are chosen to estimate the performance of the 03 methods. For each method, 02 models with 02 configurations are applied and the scores are recorded. The two configurations are Feature Extraction and Fine-tuning approaches, one prevents the weights to be updated and one makes them trainable. The final report would indicate which augmenting method is the most equitable and which approach (EX or FiT) is the best for this downstream task.</p>

## References
<p align="justify">[1] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, “BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding,” ArXiv181004805 Cs, May 2019, Accessed: May 02, 2022. [Online]. Available: http://arxiv.org/abs/1810.04805</p>
<p align="justify">[2] . Q. Nguyen and A. T. Nguyen, “PhoBERT: Pre-trained language models for Vietnamese,” ArXiv200300744 Cs, Oct. 2020, Accessed: Apr. 07, 2022. [Online]. Available: http://arxiv.org/abs/2003.00744</p>
<p align="justify">[3] N. Bertoldi and M. Federico, “Domain Adaptation for Statistical Machine Translation with Monolingual Resources,” in Proceedings of the Fourth Workshop on Statistical Machine Translation, Athens, Greece, Mar. 2009, pp. 182–189. Accessed: Apr. 23, 2022. [Online]. Available: https://aclanthology.org/W09-0432</p>
<p align="justify">[4] P. Lambert, H. Schwenk, C. Servan, and S. Abdul-Rauf, “Investigations on Translation Model Adaptation Using Monolingual Data,” in Proceedings of the Sixth Workshop on Statistical Machine Translation, Edinburgh, Scotland, Jul. 2011, pp. 284–293. Accessed: Apr. 23, 2022. [Online]. Available: https://aclanthology.org/W11-2132</p>
<p align="justify">[5] R. Sennrich, B. Haddow, and A. Birch, “Improving Neural Machine Translation Models with Monolingual Data,” in Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), Berlin, Germany, Aug. 2016, pp. 86– 96. doi: 10.18653/v1/P16-1009.</p>
<p align="justify">[6] S. Edunov, M. Ott, M. Auli, and D. Grangier, “Understanding Back-Translation at Scale,” ArXiv180809381 Cs, Oct. 2018, Accessed: Sep. 16, 2021. [Online]. Available: http://arxiv.org/abs/1808.09381</p>
<p align="justify">[7] O. Bojar and A. Tamchyna, “Improving Translation Model by Monolingual Data,” in Proceedings of the Sixth Workshop on Statistical Machine Translation, Edinburgh, Scotland, Jul. 2011, pp. 330–336. Accessed: Apr. 23, 2022. [Online]. Available: https://aclanthology.org/W11-2138</p>
<p align="justify">[8] A. Poncelas, D. Shterionov, A. Way, G. M. de B. Wenniger, and P. Passban, “Investigating Backtranslation in Neural Machine Translation,” ArXiv180406189 Cs, Apr. 2018, Accessed: Apr. 23, 2022. [Online]. Available: http://arxiv.org/abs/1804.06189</p>
<p align="justify">[9] A. Karakanta, J. Dehdari, and J. van Genabith, “Neural machine translation for low-resource languages without parallel corpora,” Mach. Transl., vol. 32, no. 1, pp. 167–189, Jun. 2018, doi: 10.1007/s10590-017-9203-5</p>
<p align="justify">[10] J. Wei and K. Zou, “EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks,” ArXiv190111196 Cs, Aug. 2019, Accessed: Jul. 15, 2021. [Online]. Available: http://arxiv.org/abs/1901.11196</p>
